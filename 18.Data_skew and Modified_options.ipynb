{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e314c722-71ea-4d3e-a943-5eeaeb3e47c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#DATA SKEW:\n",
    "\"\"\"\n",
    "Data Skew : refers to the uneven distribution of data across different partitions or buckets in a data processing system. This can lead to performance issues, particularly in distributed computing environments like big data frameworks (e.g., Hadoop, Spark) or databases.\n",
    "\"\"\"\n",
    "\n",
    "df=spark.read.option('header',True).csv('dbfs:/mnt/input/demo.csv') \n",
    "#has 800 records\n",
    "display(df)\n",
    "\n",
    "df.rdd.getNumPartitions() #1\n",
    "\n",
    "#Solution:\n",
    "df=df.repartition(10)\n",
    "df.rdd.getNumPartitions() #10\n",
    "\n",
    "#to check how many rows in each partition:\n",
    "df.select(spark_partition_id().alias(\"partid\")).groupBy('partid').count()\n",
    "\n",
    "\"\"\"\n",
    "partid.  count\n",
    "0.         79\n",
    "1          80\n",
    "2          80\n",
    "...        ...\n",
    "8           80\n",
    "9           80\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fce23158-3343-44c3-b33b-c45f3f96be21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#to process files those are received Before/After specified time:\n",
    "#option(modifiedBefore,modifiedAfter)\n",
    "\n",
    "\"\"\"\n",
    "modifiedBefore:  this attribute can be used to read files that were modified before the specified timestamp. \n",
    "\n",
    "modifiedAfter: this attribute can be used to read files that were modified after the specified timestamp.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dd6608f-89fd-46d1-a668-7b2da9f44ada",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#to process files received before the specified date.\n",
    "df1 = spark.read.option('header',True).csv(path='/mnt/input/demo.csv',\n",
    "                                           modifiedBefore='2024-01-30T00:00:00')\n",
    "display(df1)\n",
    "\n",
    "\n",
    "#to process files received after the specified date.\n",
    "df2 = spark.read.option('header',True).csv(path='/mnt/input/demo.csv',\n",
    "                                           modifiedAfter='2024-01-30T00:00:00')\n",
    "display(df2)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "18.Data_skew and Modified_options",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
